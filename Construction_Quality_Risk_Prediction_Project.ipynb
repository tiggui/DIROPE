{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 2619963,
          "sourceType": "datasetVersion",
          "datasetId": 1592437
        },
        {
          "sourceId": 11797626,
          "sourceType": "datasetVersion",
          "datasetId": 7408482
        }
      ],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Construction_Quality_Risk_Prediction_Project",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "claytonmiller_construction_and_project_management_example_data_path = kagglehub.dataset_download('claytonmiller/construction-and-project-management-example-data')\n",
        "amirgh83_construction_quality_path = kagglehub.dataset_download('amirgh83/construction-quality')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "IPc4cc0eMWVS"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Introduction\n",
        "\n",
        "## 1.1 Background\n",
        "In the construction industry, quality issues such as improper workmanship, incomplete documentation, and material non-compliance frequently lead to costly delays, rework, and disputes. Despite the use of modern project management tools and routine inspections, many issues are still identified reactively — only after they have already caused disruption.\n",
        "\n",
        "As a construction manager and researcher, I have observed the untapped potential in administrative data generated daily on construction sites. This includes task logs and daily forms submitted by field personnel. Leveraging this data with machine learning offers an opportunity to move from reactive issue detection to proactive risk prediction.\n",
        "\n",
        "## 1.2 Project Objective\n",
        "This project explores whether machine learning can be used to predict potential quality issues in construction projects using structured administrative data, without relying on sensors, photos, or BIM.\n",
        "\n",
        "The key objective is to:  \n",
        "**Build a machine learning model that predicts whether a newly submitted task record is likely to indicate a quality issue**, using features such as task group (e.g., Safety, QA/QC), cause (e.g., Documentation, Housekeeping), priority level, and overdue status.\n",
        "\n",
        "## 1.3 Key Research Question\n",
        "**Can we use routine administrative construction data to predict potential quality issues before they occur?**\n",
        "\n",
        "If successful, this project will:\n",
        "- Provide a low-cost, scalable solution using data already collected  \n",
        "- Empower field teams with smart, data-driven insights  \n",
        "- Reduce risk, rework, and delays across construction projects of all sizes\n"
      ],
      "metadata": {
        "id": "e849fdd2-c75a-47f5-9724-2045c8170c71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Understanding the Dataset\n",
        "\n",
        "## 2.1 Dataset Description\n",
        "The dataset used in this project is titled **“Construction and Project Management Example Data”**, sourced from Kaggle. It consists of two primary components:\n",
        "- Daily forms and reports submitted by field personnel (e.g., site diaries, work plans)\n",
        "- Task records, including:\n",
        "  - Task type  \n",
        "  - Task group (e.g., Safety, QA/QC)  \n",
        "  - Cause (e.g., Documentation, Housekeeping)  \n",
        "  - Overdue status  \n",
        "  - Priority level  \n",
        "  - Status (Open/Closed)\n",
        "\n",
        "Each record in this dataset reflects real-world construction field activity, making it highly relevant for quality risk modeling.\n",
        "\n",
        "## 2.2 Why This Dataset Is Relevant\n",
        "This dataset is ideal for building a predictive model because:\n",
        "- It captures real-time field-level decision-making.  \n",
        "- It includes operational indicators like **Cause**, **OverDue**, and **Priority**, which are commonly monitored by quality managers.  \n",
        "- It requires no additional data collection tools or hardware — just analysis of existing logs.\n",
        "\n",
        "**Examples:**\n",
        "- Tasks marked **\"High\" priority** often signal urgent quality or safety concerns.  \n",
        "- Causes like **\"Documentation\"** or **\"Housekeeping\"** frequently appear in non-conformance reports.  \n",
        "- **Overdue tasks** may indicate lags in resolving critical issues.\n",
        "\n",
        "These features are strong predictors for identifying potential risks.\n"
      ],
      "metadata": {
        "id": "5b5d31cf-8bc6-4ab6-a373-d6e92e1d3915"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Problem Framing\n",
        "\n",
        "## 3.1 Machine Learning Problem Type\n",
        "This project is a **supervised binary classification** task:\n",
        "\n",
        "- **Target variable:** Whether a task is a quality issue (1 = Yes, 0 = No)  \n",
        "- **Input features:** Cause, Task Group, Priority, Overdue flag, Task Type\n",
        "\n",
        "## 3.2 Labeling Strategy\n",
        "A task is labeled as a quality issue if:\n",
        "- It has a **High priority**, or  \n",
        "- It is associated with a known quality-related cause, such as **Documentation**, **Housekeeping**, or **Access**.\n",
        "\n",
        "This labeling approach aligns with how field engineers and inspectors typically flag and prioritize worksite issues.\n",
        "\n",
        "## 3.3 Potential Impact\n",
        "Once trained, the model will:\n",
        "- Take in a new task record  \n",
        "- Output a risk probability score  \n",
        "- Automatically flag risky tasks for early review  \n",
        "\n",
        "This enables construction teams to:\n",
        "- Act earlier to prevent quality failures  \n",
        "- Optimize site inspections and interventions  \n",
        "- Reduce rework, delays, and client disputes\n"
      ],
      "metadata": {
        "id": "a26da590-5350-4920-bab6-fb39885e2141"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Exploratory Data Analysis (EDA) on the Dataset\n",
        "\n",
        "## 4.1 Goal of This Step\n",
        "The purpose of exploratory data analysis is to better understand the structure of the dataset and uncover meaningful patterns or trends that will inform the selection of features for the predictive model. This step focuses on:\n",
        "\n",
        "- Understanding how key features are distributed  \n",
        "- Detecting patterns or anomalies linked to quality issues  \n",
        "- Spotting missing values, class imbalance, and other data challenges  \n",
        "\n",
        "This step focuses on the Tasks dataset, where each row represents an issue, observation, or comment logged by a construction project team.\n",
        "\n",
        "## 4.2 Load and Preview the Data\n"
      ],
      "metadata": {
        "id": "31f1026e-fbfe-4403-a1b9-39c2c44b6196"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the task dataset\n",
        "df = pd.read_csv(\"/kaggle/input/construction-and-project-management-example-data/Construction_Data_PM_Tasks_All_Projects.csv\")\n",
        "\n",
        "# Preview the first few rows\n",
        "df.head()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T15:54:20.76803Z",
          "iopub.execute_input": "2025-05-13T15:54:20.768372Z",
          "iopub.status.idle": "2025-05-13T15:54:20.873165Z",
          "shell.execute_reply.started": "2025-05-13T15:54:20.768345Z",
          "shell.execute_reply": "2025-05-13T15:54:20.872176Z"
        },
        "id": "92c7fde1-cd00-49b0-a8b2-779a3ec3a1bf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ This dataset contains 12,424 rows, each representing a construction task or issue logged in the field.\n",
        "\n",
        "## 4.3 Initial Cleaning and Feature Preparation\n",
        "Before diving into visualizations, we clean and prepare several key columns that will be used in modeling:\n"
      ],
      "metadata": {
        "id": "50313e3f-4fc0-4df8-876d-f467d6d03672"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values\n",
        "df[\"Priority\"] = df[\"Priority\"].fillna(\"None\")\n",
        "df[\"Cause\"] = df[\"Cause\"].fillna(\"Unknown\")\n",
        "df[\"Task Group\"] = df[\"Task Group\"].fillna(\"Unknown\")\n",
        "\n",
        "# Convert OverDue from boolean to integer\n",
        "df[\"OverDue\"] = df[\"OverDue\"].astype(bool).astype(int)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T15:54:58.312616Z",
          "iopub.execute_input": "2025-05-13T15:54:58.312994Z",
          "iopub.status.idle": "2025-05-13T15:54:58.324207Z",
          "shell.execute_reply.started": "2025-05-13T15:54:58.312968Z",
          "shell.execute_reply": "2025-05-13T15:54:58.323114Z"
        },
        "id": "9687e364-5a80-4149-9dca-71d50083e0e6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4 Feature Distributions and Visual Insights\n",
        "\n",
        "### 📊 1. Distribution of Task Priorities\n",
        "Understanding how task priorities are distributed in the dataset is crucial because this feature is directly tied to how construction teams assess the urgency and severity of site issues. In our model, tasks labeled as \"High\" priority will serve as the positive class, indicating a likely quality issue.\n"
      ],
      "metadata": {
        "id": "e1b28439-344c-41cd-9832-2d54cbda5c78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(data=df, x=\"Priority\", order=df[\"Priority\"].value_counts().index, palette=\"Set2\")\n",
        "plt.title(\"Distribution of Task Priorities\")\n",
        "plt.xlabel(\"Priority Level\")\n",
        "plt.ylabel(\"Number of Tasks\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T15:54:20.890492Z",
          "iopub.execute_input": "2025-05-13T15:54:20.890772Z",
          "iopub.status.idle": "2025-05-13T15:54:22.313557Z",
          "shell.execute_reply.started": "2025-05-13T15:54:20.89075Z",
          "shell.execute_reply": "2025-05-13T15:54:22.312236Z"
        },
        "id": "409b1cec-66e0-439d-8b4a-461cf81a6714"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What This Tells Us:**\n",
        "- Many tasks are labeled \"None\", \"Medium\", or include vague custom labels.\n",
        "- A relatively smaller portion of tasks are labeled \"High\", which may represent the most urgent or risk-prone issues.\n",
        "- This imbalance highlights a challenge: the model must learn from limited positive examples, which increases the risk of bias or poor recall.\n"
      ],
      "metadata": {
        "id": "63b6930f-6f0d-4735-8ee9-aca41746f10a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📊 2. Top 10 Causes of Tasks\n",
        "The `Cause` column identifies why a task was created (e.g., housekeeping failures, documentation issues). These causes often reflect quality or safety problems.\n"
      ],
      "metadata": {
        "id": "04436013-2627-4fca-8e0f-985b62f6afd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_causes = df[\"Cause\"].value_counts().nlargest(10)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=top_causes.values, y=top_causes.index, palette=\"pastel\")\n",
        "plt.title(\"Top 10 Causes of Tasks\")\n",
        "plt.xlabel(\"Number of Tasks\")\n",
        "plt.ylabel(\"Cause\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T15:54:22.314798Z",
          "iopub.execute_input": "2025-05-13T15:54:22.315362Z",
          "iopub.status.idle": "2025-05-13T15:54:22.591097Z",
          "shell.execute_reply.started": "2025-05-13T15:54:22.315326Z",
          "shell.execute_reply": "2025-05-13T15:54:22.590142Z"
        },
        "id": "449a1134-62e6-42f7-9507-4dfc56866b35"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What This Tells Us:**\n",
        "- The most frequent causes include Housekeeping, Access, and Documentation.\n",
        "- These are highly relevant to quality and safety risks and are often flagged in non-compliance reports.\n",
        "- This supports using `Cause` as a core feature in our model.\n"
      ],
      "metadata": {
        "id": "886b621d-b88c-4d2f-902b-8a9563162459"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📊 3. Overdue Status by Task Priority\n",
        "The `OverDue` column shows whether tasks were resolved on time. We expect higher-priority tasks to be more frequently overdue, indicating unresolved risk.\n"
      ],
      "metadata": {
        "id": "cef178cf-8474-4a73-b849-e2116c567593"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(data=df, x=\"Priority\", hue=\"OverDue\", order=df[\"Priority\"].value_counts().index)\n",
        "plt.title(\"Overdue Status by Task Priority\")\n",
        "plt.xlabel(\"Priority Level\")\n",
        "plt.ylabel(\"Task Count\")\n",
        "plt.legend(title=\"OverDue\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T15:54:22.593218Z",
          "iopub.execute_input": "2025-05-13T15:54:22.593508Z",
          "iopub.status.idle": "2025-05-13T15:54:22.930643Z",
          "shell.execute_reply.started": "2025-05-13T15:54:22.593483Z",
          "shell.execute_reply": "2025-05-13T15:54:22.929664Z"
        },
        "id": "9cd18423-b6b7-4d52-be03-db3178c2a5bd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What This Tells Us:**\n",
        "- High and Medium priority tasks tend to be more overdue.\n",
        "- Overdue status is correlated with severity and should be included as a predictive feature.\n"
      ],
      "metadata": {
        "id": "9105c930-38b3-47d2-b158-93e8538ff566"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📊 4. Most Common Task Groups\n",
        "The `Task Group` field helps us understand which departments most frequently log tasks — such as Safety, QA/QC, and Site Management.\n"
      ],
      "metadata": {
        "id": "d4cbf9ad-a548-4e4c-a126-5dd24ec5611c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_groups = df[\"Task Group\"].value_counts().nlargest(10)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=top_groups.values, y=top_groups.index, palette=\"muted\")\n",
        "plt.title(\"Most Common Task Groups\")\n",
        "plt.xlabel(\"Number of Tasks\")\n",
        "plt.ylabel(\"Task Group\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T15:54:22.93212Z",
          "iopub.execute_input": "2025-05-13T15:54:22.932367Z",
          "iopub.status.idle": "2025-05-13T15:54:23.127422Z",
          "shell.execute_reply.started": "2025-05-13T15:54:22.932348Z",
          "shell.execute_reply": "2025-05-13T15:54:23.126456Z"
        },
        "id": "b300a364-f5cd-4b97-bc32-d4dc7b3e0541"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What This Tells Us:**\n",
        "- Most tasks are logged by Safety and Site Management teams.\n",
        "- QA/QC and Design are also involved — likely tied to quality and compliance.\n",
        "- Task Group provides helpful context for modeling.\n"
      ],
      "metadata": {
        "id": "8bc1832c-c637-4841-8b8a-625f491734eb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.5 Summary of Key Features for Modeling\n",
        "\n",
        "| Feature      | Description                                      | Role in Prediction                      |\n",
        "|--------------|--------------------------------------------------|------------------------------------------|\n",
        "| Priority     | Indicates how urgent or severe a task is         | Used to define the target variable       |\n",
        "| Cause        | Root cause of the task (e.g., Housekeeping)      | Strong categorical predictor of quality  |\n",
        "| OverDue      | Whether the task is overdue (1 = Yes, 0 = No)    | Time-based risk signal                   |\n",
        "| Task Group   | Department responsible for the task              | Provides operational context             |\n",
        "| Type         | Nature of the task (e.g., Safety Notice)         | May reflect recurring issue patterns     |\n",
        "\n",
        "These features were selected because they align with how field engineers assess risk, and they are available in structured formats across most construction projects.\n"
      ],
      "metadata": {
        "id": "157a18fc-b12f-4d77-a64c-e972b2249cc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Data Preprocessing for Machine Learning\n",
        "\n",
        "Before training a machine learning model, I converted the raw construction task data into a clean, structured, and numerical format.\n",
        "\n",
        "In this section, we will:\n",
        "1. Define the target variable  \n",
        "2. Select relevant input features  \n",
        "3. Handle missing values  \n",
        "4. Encode categorical features  \n",
        "5. Scale numeric values  \n",
        "6. Split the dataset for training and evaluation  \n",
        "\n",
        "## 5.1 Define the Target Variable\n",
        "\n",
        "The target variable is what we want the model to predict — whether a task is a quality issue.  \n",
        "We use the `Priority` column as a proxy. If a task is labeled **High**, it’s considered a potential quality issue (`1`).  \n",
        "All other priorities are labeled as non-issues (`0`). This creates a **binary classification problem**.\n"
      ],
      "metadata": {
        "id": "386274fa-3467-4865-81b6-bcc2624679ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the target variable\n",
        "df[\"Priority\"] = df[\"Priority\"].fillna(\"None\")\n",
        "df[\"target_quality_issue\"] = df[\"Priority\"].apply(lambda x: 1 if str(x).strip().lower() == \"high\" else 0)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T15:54:23.128381Z",
          "iopub.execute_input": "2025-05-13T15:54:23.129247Z",
          "iopub.status.idle": "2025-05-13T15:54:23.14246Z",
          "shell.execute_reply.started": "2025-05-13T15:54:23.129214Z",
          "shell.execute_reply": "2025-05-13T15:54:23.141438Z"
        },
        "id": "fa6f6421-2257-4008-b301-5c6a47185ebc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Select the Input Features\n",
        "\n",
        "We select four features likely to influence whether a task is related to quality:\n",
        "\n",
        "- **Cause**: Why the task was logged (e.g., Documentation, Access)  \n",
        "- **Task Group**: Responsible team (e.g., Safety, QA/QC)  \n",
        "- **Type**: Task or form type (e.g., Safety Notice, RFI)  \n",
        "- **OverDue**: Whether the task was completed on time  \n",
        "\n",
        "These were selected because:\n",
        "- They are directly tied to how field teams monitor and escalate issues  \n",
        "- They appear in most task records  \n",
        "- They showed clear patterns during exploratory analysis  \n"
      ],
      "metadata": {
        "id": "367126f7-c980-4515-8b49-10c744c5978a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values and select features\n",
        "df[\"Cause\"] = df[\"Cause\"].fillna(\"Unknown\")\n",
        "df[\"Task Group\"] = df[\"Task Group\"].fillna(\"Unknown\")\n",
        "df[\"Type\"] = df[\"Type\"].fillna(\"Unknown\")\n",
        "df[\"OverDue\"] = df[\"OverDue\"].fillna(False).astype(int)\n",
        "\n",
        "# Define features and target\n",
        "features = [\"Cause\", \"Task Group\", \"Type\", \"OverDue\"]\n",
        "X = df[features]\n",
        "y = df[\"target_quality_issue\"]\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T15:54:23.143433Z",
          "iopub.execute_input": "2025-05-13T15:54:23.143756Z",
          "iopub.status.idle": "2025-05-13T15:54:23.168019Z",
          "shell.execute_reply.started": "2025-05-13T15:54:23.143725Z",
          "shell.execute_reply": "2025-05-13T15:54:23.167018Z"
        },
        "id": "6dd0a1b5-f934-412d-853f-59e932f3c484"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3 Split into Training, Validation, and Test Sets\n",
        "\n",
        "To evaluate the model fairly, we split the dataset into:\n",
        "\n",
        "- **Training Set (64%)** — used to train the model  \n",
        "- **Validation Set (16%)** — used to tune and test the model during development  \n",
        "- **Test Set (20%)** — used for final evaluation  \n",
        "\n",
        "Stratified sampling ensures that the ratio of quality issues (`1`) to non-issues (`0`) stays consistent in each split.\n"
      ],
      "metadata": {
        "id": "fa1435a3-c4a9-423e-b9c8-52ed5e01694c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# First split: temp (train + val) and test\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Second split: train and val\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.2, stratify=y_temp, random_state=42)\n",
        "\n",
        "# Display split sizes\n",
        "print(\"Training set size:\", X_train.shape)\n",
        "print(\"Validation set size:\", X_val.shape)\n",
        "print(\"Test set size:\", X_test.shape)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T15:55:09.722007Z",
          "iopub.execute_input": "2025-05-13T15:55:09.72237Z",
          "iopub.status.idle": "2025-05-13T15:55:09.743004Z",
          "shell.execute_reply.started": "2025-05-13T15:55:09.722346Z",
          "shell.execute_reply": "2025-05-13T15:55:09.742098Z"
        },
        "id": "63d2cb3a-7edb-4706-a43c-eed3d06e1cdc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.4 Encode and Scale the Features\n",
        "\n",
        "Machine learning algorithms require numeric inputs. We process features in two steps:\n",
        "\n",
        "### 🔤 One-Hot Encoding (Categorical Columns)\n",
        "We convert categorical features into binary columns. For example:\n",
        "- `Cause = Documentation` becomes a column called `Cause_Documentation`\n",
        "\n",
        "### 📏 Standard Scaling (Numeric Columns)\n",
        "We scale the `OverDue` column so that its values have a mean of 0 and standard deviation of 1.\n",
        "\n",
        "We'll use **scikit-learn pipelines** to clean, encode, and scale the data consistently.\n"
      ],
      "metadata": {
        "id": "b17d52c9-ff68-470f-94a5-fd59a90c3e35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Define categorical and numeric columns\n",
        "categorical_cols = [\"Cause\", \"Task Group\", \"Type\"]\n",
        "numeric_cols = [\"OverDue\"]\n",
        "\n",
        "# Categorical pipeline\n",
        "categorical_pipeline = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "# Numeric pipeline\n",
        "numeric_pipeline = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "# Combine the pipelines\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"cat\", categorical_pipeline, categorical_cols),\n",
        "    (\"num\", numeric_pipeline, numeric_cols)\n",
        "])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T15:55:20.559223Z",
          "iopub.execute_input": "2025-05-13T15:55:20.55953Z",
          "iopub.status.idle": "2025-05-13T15:55:20.566891Z",
          "shell.execute_reply.started": "2025-05-13T15:55:20.559508Z",
          "shell.execute_reply": "2025-05-13T15:55:20.565495Z"
        },
        "id": "f3932a0c-1fc6-44b5-a20c-7f33d49ff280"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.5 Apply Transformations to the Data\n",
        "\n",
        "We apply the preprocessing pipeline to the training, validation, and test sets.\n"
      ],
      "metadata": {
        "id": "6ee600bb-8303-49bd-9c33-00c60f311bd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit on training, transform all\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_val_processed = preprocessor.transform(X_val)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "# Confirm output shapes\n",
        "print(\"Training shape:\", X_train_processed.shape)\n",
        "print(\"Validation shape:\", X_val_processed.shape)\n",
        "print(\"Test shape:\", X_test_processed.shape)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T15:54:23.720266Z",
          "iopub.execute_input": "2025-05-13T15:54:23.720537Z",
          "iopub.status.idle": "2025-05-13T15:54:23.772389Z",
          "shell.execute_reply.started": "2025-05-13T15:54:23.720515Z",
          "shell.execute_reply": "2025-05-13T15:54:23.771496Z"
        },
        "id": "ab7604b1-29b6-496e-b1e9-37be5fc0217b"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Model Training: Logistic Regression\n",
        "\n",
        "Now that the dataset is preprocessed, we move to model training. The objective is to build a model that can accurately classify construction tasks as either quality issues (1) or non-issues (0) using the selected features.\n",
        "\n",
        "## 6.1 Selecting Logistic Regression for Baseline Modeling\n",
        "\n",
        "Logistic Regression is chosen as the initial model because it combines:\n",
        "\n",
        "- **Simplicity**: Easy to understand and implement.\n",
        "- **Interpretability**: Coefficients explain each feature’s influence on risk.\n",
        "- **Efficiency**: Fast to train even on large datasets.\n",
        "- **Balance Handling**: Supports `class_weight='balanced'` to account for rare quality issues.\n",
        "\n",
        "This makes it an ideal field-friendly, transparent baseline before testing more complex models.\n",
        "\n",
        "## 6.2 Training the Model\n",
        "\n",
        "We use the `scikit-learn` library to initialize and train the logistic regression model.\n"
      ],
      "metadata": {
        "id": "9d1632b0-f7c0-43c6-9832-64967d58a909"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Initialize the logistic regression model\n",
        "model = LogisticRegression(\n",
        "    max_iter=1000,              # Avoid premature convergence\n",
        "    class_weight='balanced',   # Handle class imbalance\n",
        "    random_state=42            # Reproducibility\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_processed, y_train)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T15:54:23.773338Z",
          "iopub.execute_input": "2025-05-13T15:54:23.77356Z",
          "iopub.status.idle": "2025-05-13T15:54:23.923972Z",
          "shell.execute_reply.started": "2025-05-13T15:54:23.773545Z",
          "shell.execute_reply": "2025-05-13T15:54:23.922125Z"
        },
        "id": "7bb39915-b4bb-4eb6-b6d6-ea8f96712bc8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.3 Validation and Evaluation\n",
        "\n",
        "After training, we evaluate the model on the validation set to assess how well it generalizes to unseen data.\n"
      ],
      "metadata": {
        "id": "82b047fd-2e1a-412f-844b-73f80d430887"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict class labels and probabilities\n",
        "y_val_pred = model.predict(X_val_processed)\n",
        "y_val_prob = model.predict_proba(X_val_processed)[:, 1]\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T15:54:23.924638Z",
          "iopub.execute_input": "2025-05-13T15:54:23.924888Z",
          "iopub.status.idle": "2025-05-13T15:54:23.950086Z",
          "shell.execute_reply.started": "2025-05-13T15:54:23.924867Z",
          "shell.execute_reply": "2025-05-13T15:54:23.94935Z"
        },
        "id": "4daff8f9-19e5-4b2d-8770-97e67c94b2cb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📊 6.4 Performance Summary\n",
        "\n",
        "Key evaluation metrics:\n",
        "\n",
        "- **Accuracy**: ~83.7%\n",
        "- **Recall (for quality issues)**: ~97%\n",
        "- **Precision (for quality issues)**: ~9%\n",
        "- **ROC AUC Score**: ~0.83\n",
        "\n",
        "### What These Metrics Mean:\n",
        "\n",
        "- **Accuracy** is high, but not fully reliable in imbalanced datasets.\n",
        "- **Recall** is excellent (~97%), meaning the model catches almost all true quality issues.\n",
        "- **Precision** is low (~9%), indicating many false positives — which may be acceptable in safety-critical fields.\n",
        "- **ROC AUC Score** of ~0.83 shows strong ability to separate risky from normal tasks.\n",
        "\n",
        "> ROC = Receiver Operating Characteristic  \n",
        "> AUC = Area Under the Curve — measures how well the model ranks true positives higher than negatives.\n"
      ],
      "metadata": {
        "id": "bf53c7bd-7747-4256-8117-07990babb892"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.5 Interpretation\n",
        "\n",
        "The results reflect common trade-offs in construction risk modeling:\n",
        "\n",
        "- High **recall** ensures we rarely miss real problems.\n",
        "- Low **precision** means we flag many false alarms, but this is acceptable when safety is a priority.\n",
        "- The model becomes a proactive assistant, guiding field engineers to investigate high-risk tasks first.\n",
        "\n",
        "**Example**:  \n",
        "A superintendent gets a flagged list every morning. Even one early warning about poor documentation could prevent costly rework.\n"
      ],
      "metadata": {
        "id": "73add379-5f73-4001-97a0-c2bff594da56"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.6 How the Model Aligns with Project Objectives\n",
        "\n",
        "This model supports our goals in multiple ways:\n",
        "\n",
        "- **Early Detection**: Predicts which tasks pose quality risks.\n",
        "- **Explainability**: Coefficients clarify why a task was flagged.\n",
        "- **Rare Case Handling**: `class_weight='balanced'` addresses low-frequency critical tasks.\n",
        "- **Efficiency**: Lightweight and easy to retrain or deploy in a construction field environment.\n",
        "\n",
        "We don’t need a perfect model — we need a reliable one that supports proactive risk management and communicates its logic clearly.\n"
      ],
      "metadata": {
        "id": "38271510-3bb3-4d5c-8c5d-22dd4f32db61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.7 What the Model Learns\n",
        "\n",
        "Logistic Regression assigns a **coefficient** (weight) to each feature:\n",
        "\n",
        "- A **positive coefficient** increases the likelihood a task is labeled a quality issue.\n",
        "- A **negative coefficient** reduces that likelihood.\n",
        "\n",
        "This allows teams to interpret and trust model outputs — making the results actionable, not just predictive.\n"
      ],
      "metadata": {
        "id": "c37c70e1-a5b6-4215-9678-96776718451b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Model Evaluation and Insights\n",
        "\n",
        "After training the Logistic Regression model, we assess how well it performs on unseen data using the validation set. This evaluation addresses several key questions:\n",
        "\n",
        "- How accurate is the model overall?\n",
        "- Can it reliably detect actual quality issues?\n",
        "- Does it generate too many false alarms?\n",
        "- Is it effective enough to support field decision-making?\n"
      ],
      "metadata": {
        "id": "2902c608-1c69-4239-8951-ec61ac350da4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📊 7.1 Confusion Matrix\n",
        "\n",
        "The confusion matrix breaks predictions into four categories:\n",
        "\n",
        "- **True Positives (TP)**: Correctly flagged quality issues\n",
        "- **True Negatives (TN)**: Correctly identified non-issues\n",
        "- **False Positives (FP)**: Normal tasks incorrectly flagged\n",
        "- **False Negatives (FN)**: Missed quality issues\n",
        "\n",
        "In our results:\n",
        "\n",
        "- ✅ TP = 33\n",
        "- ❌ FN = 1\n",
        "- ✅ TN = 1,632\n",
        "- ❌ FP = 322\n",
        "\n",
        "👉 The model is **highly sensitive** (catches most real issues) but slightly over-cautious (raises some false alarms), which is acceptable in construction settings where missing a real issue is riskier.\n"
      ],
      "metadata": {
        "id": "8dd6e52a-d381-4a55-a10e-d739dd468744"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📈 7.2 ROC Curve (Receiver Operating Characteristic)\n",
        "\n",
        "The ROC curve shows the trade-off between recall (sensitivity) and specificity across all thresholds.\n",
        "\n",
        "- **AUC = 0.83**, which is considered strong.\n",
        "- AUC (Area Under the Curve) ranges from 0.5 (random guessing) to 1.0 (perfect classification).\n",
        "\n",
        "✅ This means the model does a solid job separating risky from non-risky tasks.\n"
      ],
      "metadata": {
        "id": "40146058-c93b-4e2f-a9e7-8287317d915d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📉 7.3 Precision-Recall Curve\n",
        "\n",
        "In imbalanced datasets like ours, the Precision-Recall Curve is very informative.\n",
        "\n",
        "- **Recall ~97%** → The model catches nearly all true quality issues.\n",
        "- **Precision ~9%** → Only about 1 in 11 flagged tasks is truly an issue.\n",
        "\n",
        "This indicates the model casts a wide net. While it generates many false positives, it's more cautious than conservative — a safer approach in construction risk mitigation.\n"
      ],
      "metadata": {
        "id": "7a03c7a2-f23f-46a3-bf5c-6a6098904848"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📌 7.4 Summary of Evaluation Results\n",
        "\n",
        "- **Accuracy ~83.7%**: Good overall but can be misleading in imbalanced datasets.\n",
        "- **Recall ~97%**: Excellent at detecting real issues.\n",
        "- **Precision ~9%**: Lower, which leads to more false positives.\n",
        "- **AUC ~0.83**: Strong at ranking task risk.\n",
        "\n",
        "🎯 Overall, this model prioritizes safety by flagging anything potentially risky — ideal for field usage.\n"
      ],
      "metadata": {
        "id": "a8cfe752-f4b3-4827-9b6b-9eadfba4dc05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ 7.5 Strengths of the Model\n",
        "\n",
        "1. **High Recall**: Rarely misses actual quality issues.\n",
        "2. **Interpretable**: Logistic Regression offers feature weights that are easy to explain.\n",
        "3. **Lightweight & Adaptable**: Easy to retrain with new data.\n",
        "\n",
        "These make it an excellent baseline tool for field engineers and project managers.\n"
      ],
      "metadata": {
        "id": "1a0cc342-24ea-4351-bfcd-adb38efa0882"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ⚠️ 7.6 Limitations of the Model\n",
        "\n",
        "1. **Low Precision**: Generates many false alarms.\n",
        "2. **Class Imbalance**: Few “High” priority tasks may limit the learning depth.\n",
        "3. **Model Simplicity**: Logistic Regression may not capture complex feature interactions.\n",
        "\n",
        "These are common challenges in early-stage models and provide direction for further improvement.\n"
      ],
      "metadata": {
        "id": "f43f66aa-c62c-4224-b7ae-c734b77bfa4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔧 7.7 What Can Be Improved Next\n",
        "\n",
        "To boost performance, especially precision, the following strategies can be explored:\n",
        "\n",
        "- **SMOTE or Undersampling**: Balance the dataset by adjusting class ratios.\n",
        "- **Advanced Models**: Try Random Forest, XGBoost, or Neural Networks for better pattern recognition.\n",
        "- **Feature Engineering**: Add context with features like time of day, recurrence history, or project phase.\n",
        "- **Hyperparameter Tuning**: Adjust regularization, thresholds, and solver choices.\n",
        "\n",
        "These steps will help build a more robust model that balances caution and accuracy.\n"
      ],
      "metadata": {
        "id": "929ae5da-3793-4c61-a6f7-3a2cd94aedee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1f9e32e5-d63a-4255-96e6-89838a444e2a"
      }
    }
  ]
}